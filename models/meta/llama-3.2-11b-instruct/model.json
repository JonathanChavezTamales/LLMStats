{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "Llama 3.2 11B Instruct",
  "description": "Llama 3.2 11B Vision Instruct is an instruction-tuned multimodal large language model optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. It accepts text and images as input and generates text as output.",
  "release_date": "2024-09-25",
  "input_context_size": 128000,
  "output_context_size": 128000,
  "license": "Llama 3.2 Community License",
  "multimodal": true,
  "web_hydrated": false,
  "knowledge_cutoff": "2023-12-31",
  "api_ref_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
  "playground_link": null,
  "paper_link": null,
  "scorecard_blog_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
  "repo_link": "https://github.com/facebookresearch/llama",
  "weights_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
  "param_count": 10600000000,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "VQAv2 (test)",
      "score": 0.752,
      "is_self_reported": true,
      "analysis_method": "Accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MMLU",
      "score": 0.73,
      "is_self_reported": true,
      "analysis_method": "Macro average accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MMMU",
      "score": 0.507,
      "is_self_reported": true,
      "analysis_method": "Val, 0-shot CoT, micro avg accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MMMU-Pro",
      "score": 0.33,
      "is_self_reported": true,
      "analysis_method": "Test accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MathVista",
      "score": 0.515,
      "is_self_reported": true,
      "analysis_method": "Test accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "ChartQA",
      "score": 0.834,
      "is_self_reported": true,
      "analysis_method": "Test, 0-shot CoT relaxed accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "AI2D",
      "score": 0.911,
      "is_self_reported": true,
      "analysis_method": "Test accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "DocVQA",
      "score": 0.884,
      "is_self_reported": true,
      "analysis_method": "Test ANLS",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MATH",
      "score": 0.519,
      "is_self_reported": true,
      "analysis_method": "0-shot, CoT",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.328,
      "is_self_reported": true,
      "analysis_method": "0-shot, CoT",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MGSM",
      "score": 0.689,
      "is_self_reported": true,
      "analysis_method": "0-shot, CoT",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    }
  ]
}
