{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": "llama-3.1-70b-instruct",
  "name": "Llama 3.1 Nemotron 70B Instruct",
  "description": "A large language model customized by NVIDIA to improve the helpfulness of LLM generated responses. It is a fine-tuned version of Llama 3.1 70B Instruct. The model was trained using RLHF (REINFORCE) with HelpSteer2-Preference prompts.",
  "release_date": "2024-10-01",
  "input_context_size": 128000,
  "output_context_size": 4000,
  "license": "Llama 3.1 Community License",
  "multimodal": false,
  "web_hydrated": false,
  "knowledge_cutoff": "2023-12-01",
  "api_ref_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct",
  "playground_link": null,
  "paper_link": "https://arxiv.org/abs/2410.01257",
  "scorecard_blog_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
  "repo_link": null,
  "weights_link": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct",
  "param_count": 70000000000,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "Winogrande",
      "score": 0.8453,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "ARC-C",
      "score": 0.692,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "MMLU",
      "score": 0.802,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "HellaSwag",
      "score": 0.8558,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "GSM8K",
      "score": 0.9143,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "TruthfulQA",
      "score": 0.5863,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "XLSum English",
      "score": 0.3161,
      "is_self_reported": true,
      "analysis_method": "Standard evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "MMLU Chat",
      "score": 0.8058,
      "is_self_reported": true,
      "analysis_method": "Chat evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "GSM8K Chat",
      "score": 0.8188,
      "is_self_reported": true,
      "analysis_method": "Chat evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "Instruct HumanEval",
      "score": 0.7384,
      "is_self_reported": true,
      "analysis_method": "Code evaluation (n=20)",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    },
    {
      "dataset_name": "MT-Bench",
      "score": 8.99,
      "is_self_reported": true,
      "analysis_method": "Chat evaluation",
      "date_recorded": "2024-10-01",
      "source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/"
    }
  ]
}
