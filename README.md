# LLM-Stats ğŸ“Š

[![GitHub stars](https://img.shields.io/github/stars/JonathanChavezTamales/LLMStats?style=social)](https://github.com/JonathanChavezTamales/LLMStats/stargazers)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![Issues](https://img.shields.io/github/issues/JonathanChavezTamales/LLMStats)](https://github.com/JonathanChavezTamales/llm-stats/issues)

A community-driven repository of LLM data and benchmarks. Compare and explore language models through our interactive dashboard at [llm-stats.com](https://llm-stats.com).

## ğŸ” What's Inside

Our repository contains detailed information on hundreds of LLMs:

- Model parameters, context window sizes, licensing details, capabilities, and more
- Provider pricing
- Performance metrics (throughput, latency)
- Standardized benchmark results

## ğŸ¤ How to Contribute

We welcome community contributions to keep our data accurate and up-to-date:

1. **Update Model Data**

   - Browse [`models/`](models/) and [`providers/`](providers/) directories
   - Submit a PR following our [contribution guidelines](CONTRIBUTING.md)
   - Check [`schemas/`](schemas/) for data formats

2. **Report Issues with llm-stats.com**
   - Have a feature request or found a bug? [Open an issue](https://github.com/JonathanChavezTamales/LLMStats/issues)

## ğŸ“ˆ Data Quality

Accuracy is our priority. To ensure reliable information:

- All benchmark data requires verifiable source links
- Community review process for all changes
- Multiple source citations encouraged
- Regular validation of submitted data

There's no guarantee that the data is 100% accurate, but we do our best to ensure it's as accurate as possible.

<!-- ## ğŸŒŸ Community
- Join our [Discord](https://discord.gg/llmstats) for discussions
-->

---

<div align="center">
Built with ğŸ’™ by the AI community, for the AI community.<br>
Star this repo if you find it useful!
</div>
